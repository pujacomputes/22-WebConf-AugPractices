{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from utils import load_file, preprocessing, get_vocab, load_embeddings, create_gows, accuracy, generate_batches, AverageMeter\n",
    "from models import MPAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args['path_to_dataset'] = '../datasets/subjectivity.txt'\n",
    "args['path_to_embeddings'] = \"../GoogleNews-vectors-negative300.bin\"\n",
    "args['no_cuda'] = False\n",
    "args['epochs'] = 200\n",
    "args['lr'] = 0.001\n",
    "args['hidden'] = 64\n",
    "args['penultimate'] = 64\n",
    "args['message_passing_layers']=2\n",
    "args['window_size'] = 2\n",
    "args['directed'] = True\n",
    "args['use_master_node'] = True\n",
    "args['normalize'] = True\n",
    "args['dropout'] = 0.5\n",
    "args['batch_size'] = 128\n",
    "args['patience'] = 20\n",
    "args = dotdict(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "docs, class_labels = load_file(args.path_to_dataset)\n",
    "docs = preprocessing(docs)\n",
    "\n",
    "enc = LabelEncoder()\n",
    "class_labels = enc.fit_transform(class_labels)\n",
    "\n",
    "nclass = np.unique(class_labels).size\n",
    "y = list()\n",
    "for i in range(len(class_labels)):\n",
    "    t = np.zeros(1)\n",
    "    t[0] = class_labels[i]\n",
    "    y.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = get_vocab(docs)\n",
    "embeddings = load_embeddings(\"../GoogleNews-vectors-negative300.bin\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj, features, _ = create_gows(docs, vocab, args.window_size, args.directed, args.normalize, args.use_master_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADJ:    (0, 21)\t1.0\n",
      "  (1, 21)\t0.5\n",
      "  (1, 0)\t0.5\n",
      "  (2, 21)\t0.5\n",
      "  (2, 1)\t0.5\n",
      "  (3, 21)\t0.5\n",
      "  (3, 2)\t0.5\n",
      "  (4, 21)\t0.5\n",
      "  (4, 3)\t0.5\n",
      "  (5, 21)\t0.3333333333333333\n",
      "  (5, 10)\t0.3333333333333333\n",
      "  (5, 4)\t0.3333333333333333\n",
      "  (6, 21)\t0.5\n",
      "  (6, 5)\t0.5\n",
      "  (7, 21)\t0.3333333333333333\n",
      "  (7, 17)\t0.3333333333333333\n",
      "  (7, 6)\t0.3333333333333333\n",
      "  (8, 21)\t0.5\n",
      "  (8, 7)\t0.5\n",
      "  (9, 21)\t0.5\n",
      "  (9, 8)\t0.5\n",
      "  (10, 21)\t0.5\n",
      "  (10, 9)\t0.5\n",
      "  (11, 21)\t0.5\n",
      "  (11, 5)\t0.5\n",
      "  :\t:\n",
      "  (19, 21)\t0.5\n",
      "  (19, 18)\t0.5\n",
      "  (20, 21)\t0.5\n",
      "  (20, 19)\t0.5\n",
      "  (21, 20)\t0.047619047619047616\n",
      "  (21, 19)\t0.047619047619047616\n",
      "  (21, 18)\t0.047619047619047616\n",
      "  (21, 17)\t0.047619047619047616\n",
      "  (21, 16)\t0.047619047619047616\n",
      "  (21, 15)\t0.047619047619047616\n",
      "  (21, 14)\t0.047619047619047616\n",
      "  (21, 13)\t0.047619047619047616\n",
      "  (21, 12)\t0.047619047619047616\n",
      "  (21, 11)\t0.047619047619047616\n",
      "  (21, 10)\t0.047619047619047616\n",
      "  (21, 9)\t0.047619047619047616\n",
      "  (21, 8)\t0.047619047619047616\n",
      "  (21, 7)\t0.047619047619047616\n",
      "  (21, 6)\t0.047619047619047616\n",
      "  (21, 5)\t0.047619047619047616\n",
      "  (21, 4)\t0.047619047619047616\n",
      "  (21, 3)\t0.047619047619047616\n",
      "  (21, 2)\t0.047619047619047616\n",
      "  (21, 1)\t0.047619047619047616\n",
      "  (21, 0)\t0.047619047619047616\n",
      "FEAT:  [    1     2     3     4     5     6     7     8     9    10    11    12\n",
      "    13    14    15    16    17    18    19    20    21 21322]\n"
     ]
    }
   ],
   "source": [
    "print(\"ADJ: \",adj[0])\n",
    "print(\"FEAT: \",features[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Adj\" is a list of sparse tensors. \"Features\" is a list of np arrays where \"features[0]\" corresponds to a single graph, size = num nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=2, shuffle=True)\n",
    "it = 0\n",
    "accs = list()\n",
    "train_index, test_index =  kf.split(y)\n",
    "train_index = train_index[0]\n",
    "test_index = test_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.permutation(train_index)\n",
    "train_index = idx[:int(idx.size*0.9)].tolist()\n",
    "val_index = idx[int(idx.size*0.9):].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:  4500\n",
      "VAL:  500\n",
      "TEST:  5000\n"
     ]
    }
   ],
   "source": [
    "n_train = len(train_index)\n",
    "n_val = len(val_index)\n",
    "n_test = len(test_index)\n",
    "\n",
    "print(\"TRAIN: \",n_train)\n",
    "print(\"VAL: \",n_val)\n",
    "print(\"TEST: \",n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_train = [adj[i] for i in train_index]\n",
    "features_train = [features[i] for i in train_index]\n",
    "y_train = [y[i] for i in train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_val = [adj[i] for i in val_index]\n",
    "features_val = [features[i] for i in val_index]\n",
    "y_val = [y[i] for i in val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_test = [adj[i] for i in test_index]\n",
    "features_test = [features[i] for i in test_index]\n",
    "y_test = [y[i] for i in test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_train, features_train, batch_n_graphs_train, y_train = generate_batches(adj_train, features_train, y_train, args.batch_size, args.use_master_node)\n",
    "adj_val, features_val, batch_n_graphs_val, y_val = generate_batches(adj_val, features_val, y_val, args.batch_size, args.use_master_node)\n",
    "adj_test, features_test, batch_n_graphs_test, y_test = generate_batches(adj_test, features_test, y_test, args.batch_size, args.use_master_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[   1,   44,    2,  ..., 5721, 5722, 5723],\n",
       "                       [   0,    0,    1,  ..., 5759, 5759, 5759]]),\n",
       "       values=tensor([0.3333, 0.0714, 0.3333,  ..., 0.5000, 0.5000, 0.5000]),\n",
       "       size=(5760, 5760), nnz=7826, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_batches = ceil(n_train/args.batch_size)\n",
    "n_val_batches = ceil(n_val/args.batch_size)\n",
    "n_test_batches = ceil(n_test/args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and optimizer\n",
    "model = MPAD(embeddings.shape[1], args.message_passing_layers, args.hidden, args.penultimate, nclass, args.dropout, embeddings, args.use_master_node)\n",
    "\n",
    "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = optim.Adam(parameters, lr=args.lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPAD(\n",
       "  (embedding): Embedding(21323, 300)\n",
       "  (mps): ModuleList(\n",
       "    (0): MessagePassing(\n",
       "      (mlp1): MLP(\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=300, out_features=64, bias=True)\n",
       "          (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (batch_norms): ModuleList(\n",
       "          (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (mlp2): MLP(\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (batch_norms): ModuleList(\n",
       "          (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (fc1_update): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (fc2_update): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (fc1_reset): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (fc2_reset): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (1): MessagePassing(\n",
       "      (mlp1): MLP(\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (batch_norms): ModuleList(\n",
       "          (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (mlp2): MLP(\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (batch_norms): ModuleList(\n",
       "          (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (fc1_update): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (fc2_update): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (fc1_reset): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (fc2_reset): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (atts): ModuleList(\n",
       "    (0): Attention(\n",
       "      (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (fc2): Linear(in_features=64, out_features=1, bias=False)\n",
       "      (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (softmax): Softmax(dim=1)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Attention(\n",
       "      (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (fc2): Linear(in_features=64, out_features=1, bias=False)\n",
       "      (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (softmax): Softmax(dim=1)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.cuda:\n",
    "    model.cuda()\n",
    "    adj_train = [x.cuda() for x in adj_train]\n",
    "    features_train = [x.cuda() for x in features_train]\n",
    "    batch_n_graphs_train = [x.cuda() for x in batch_n_graphs_train]\n",
    "    y_train = [x.cuda() for x in y_train]\n",
    "    adj_val = [x.cuda() for x in adj_val]\n",
    "    features_val = [x.cuda() for x in features_val]\n",
    "    batch_n_graphs_val = [x.cuda() for x in batch_n_graphs_val]\n",
    "    y_val = [x.cuda() for x in y_val]\n",
    "    adj_test = [x.cuda() for x in adj_test]\n",
    "    features_test = [x.cuda() for x in features_test]\n",
    "    batch_n_graphs_test = [x.cuda() for x in batch_n_graphs_test]\n",
    "    y_test = [x.cuda() for x in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, adj, features, batch_n_graphs, y):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(features, adj, batch_n_graphs)\n",
    "    loss_train = F.cross_entropy(output, y)\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    return output, loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(adj, features, batch_n_graphs, y):\n",
    "    output = model(features, adj, batch_n_graphs)\n",
    "    loss_test = F.cross_entropy(output, y)\n",
    "    return output, loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sc/libraries/torch_loc/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-val iter: 00 epoch: 001 train_loss= 0.38416 train_acc= 0.82156 val_loss= 0.93262 val_acc= 0.48200 time= 4.26239\n",
      "Cross-val iter: 00 epoch: 002 train_loss= 0.26914 train_acc= 0.88911 val_loss= 0.23591 val_acc= 0.91000 time= 3.88161\n",
      "Cross-val iter: 00 epoch: 003 train_loss= 0.25339 train_acc= 0.89756 val_loss= 0.22240 val_acc= 0.91600 time= 3.80845\n",
      "Cross-val iter: 00 epoch: 004 train_loss= 0.24279 train_acc= 0.89800 val_loss= 0.20379 val_acc= 0.91800 time= 3.88065\n",
      "Cross-val iter: 00 epoch: 005 train_loss= 0.22588 train_acc= 0.90956 val_loss= 0.21516 val_acc= 0.93000 time= 3.88223\n",
      "Cross-val iter: 00 epoch: 006 train_loss= 0.20462 train_acc= 0.92067 val_loss= 0.23471 val_acc= 0.92800 time= 3.85874\n",
      "EarlyStopping: 1 / 20\n",
      "Cross-val iter: 00 epoch: 007 train_loss= 0.19792 train_acc= 0.92222 val_loss= 0.20442 val_acc= 0.92800 time= 3.90551\n",
      "EarlyStopping: 2 / 20\n",
      "Cross-val iter: 00 epoch: 008 train_loss= 0.20416 train_acc= 0.91889 val_loss= 0.20465 val_acc= 0.93000 time= 3.65842\n",
      "Cross-val iter: 00 epoch: 009 train_loss= 0.19149 train_acc= 0.92356 val_loss= 0.21299 val_acc= 0.92400 time= 3.62521\n",
      "EarlyStopping: 1 / 20\n",
      "Cross-val iter: 00 epoch: 010 train_loss= 0.17349 train_acc= 0.93133 val_loss= 0.20397 val_acc= 0.93200 time= 39.59920\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-595e47a6f21d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_train_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_n_graphs_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtrain_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-2673e4a1acf5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, adj, features, batch_n_graphs, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_n_graphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_n_graphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mloss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mloss_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sc/libraries/torch_loc/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sc/eslubana/graphssl/mpad/mpad/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, adj, n_graphs)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mlst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sc/libraries/torch_loc/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sc/libraries/torch_loc/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             self.weight, self.bias, bn_training, exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sc/libraries/torch_loc/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2146\u001b[0m     return torch.batch_norm(\n\u001b[0;32m-> 2147\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2148\u001b[0m     )\n\u001b[1;32m   2149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    scheduler.step()\n",
    "\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    train_loss = AverageMeter()\n",
    "    train_acc = AverageMeter()\n",
    "\n",
    "    # Train for one epoch\n",
    "    for i in range(n_train_batches):\n",
    "        output, loss = train(epoch, adj_train[i], features_train[i], batch_n_graphs_train[i], y_train[i])\n",
    "        train_loss.update(loss.item(), output.size(0))\n",
    "        train_acc.update(accuracy(output.data, y_train[i].data), output.size(0))\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    val_loss = AverageMeter()\n",
    "    val_acc = AverageMeter()\n",
    "\n",
    "    for i in range(n_val_batches):\n",
    "        output, loss = test(adj_val[i], features_val[i], batch_n_graphs_val[i], y_val[i])\n",
    "        val_loss.update(loss.item(), output.size(0))\n",
    "        val_acc.update(accuracy(output.data, y_val[i].data), output.size(0))\n",
    "\n",
    "    # Print results\n",
    "    print(\"Cross-val iter:\", '%02d' % it, \"epoch:\", '%03d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(train_loss.avg),\n",
    "        \"train_acc=\", \"{:.5f}\".format(train_acc.avg), \"val_loss=\", \"{:.5f}\".format(val_loss.avg),\n",
    "        \"val_acc=\", \"{:.5f}\".format(val_acc.avg), \"time=\", \"{:.5f}\".format(time.time() - start))\n",
    "\n",
    "    # Remember best accuracy and save checkpoint\n",
    "    is_best = val_acc.avg >= best_acc\n",
    "    best_acc = max(val_acc.avg, best_acc)\n",
    "    if is_best:\n",
    "        early_stopping_counter = 0\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, 'model_best.pth.tar')\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        print(\"EarlyStopping: %i / %i\" % (early_stopping_counter, args.patience))\n",
    "        if early_stopping_counter == args.patience:\n",
    "            print(\"EarlyStopping: Stop training\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
